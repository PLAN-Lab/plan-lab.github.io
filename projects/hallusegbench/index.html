---
layout: project
title: HalluSegBench
---

<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="Counterfactual Visual Reasoning for Segmentation Hallucination Evaluation">
  <meta name="keywords" content="reasoning segmentation, hallucination, counterfactual">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Counterfactual Visual Reasoning for Segmentation Hallucination Evaluations</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.ico">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>


<body>
<!-- {% include navbar.html %} -->
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-2 publication-title" style="font-size:2.4rem;"><img src="static/images/logo.png" alt="HalluSegBench logo"
                width="80px"><span class="model-name-gradient">HalluSegBench</span>: Counterfactual Visual Reasoning for Segmentation Hallucination Evaluation</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://www.linkedin.com/in/xinzhuo-li/" class="illini-blue">Xinzhuo Li<sup class="illini-orange">*</sup></a>,</span>
              <span class="author-block">
                <a href="https://www.linkedin.com/in/juvekaradheesh/" class="illini-blue">Adheesh Juvekar<sup class="illini-orange">*</sup></a>,</span>
              <span class="author-block">
                <a href="https://www.linkedin.com/in/xingyou-liu-aa216b1b6/" class="illini-blue">Xingyou Liu</a>,</span>
              </span>
              <span class="author-block">
                <a href="https://mwahed.com/" class="illini-blue">Muntasir Wahed</a>,
              <span class="author-block">
                <a href="https://www.linkedin.com/in/kanguyen-vn/" class="illini-blue">Kiet A. Nguyen</a>,</span>             
              </span>
              <span class="author-block">
                <a href="https://isminoula.github.io/" class="illini-blue">Ismini Lourentzou</a>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><a href="https://plan-lab.github.io/">PLAN Lab</a></span>,
              <span class="author-block illini-orange">University of Illinois Urbana-Champaign</span>
            </div>

             <div class="is-size-5 publication-authors">
              <span class="illini-blue"><span class="illini-orange">*</span> Equal Contribution</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="." class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="." class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="." class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://huggingface.co/datasets/PLAN-Lab/HalluSegBench" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>Data</span>
                  </a>
                </span>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Recent progress in vision-language segmentation has significantly advanced grounded visual understanding. 
              However, these models often exhibit hallucinations by producing segmentation masks for objects not grounded in the image content or by incorrectly labeling irrelevant regions. 
              Existing evaluation protocols for segmentation hallucination primarily focus on label or textual hallucinations without manipulating the visual context, limiting their capacity to diagnose critical failures. 
              In response, we introduce <span class="model-name-gradient">HalluSegBench</span>, the first benchmark specifically designed to evaluate hallucinations in visual grounding through the lens of <span style="font-style: italic;">counterfactual visual reasoning</span>. 
              Our benchmark consists of a novel dataset of $1340$ counterfactual instance pairs spanning $281$ unique object classes, and a set of newly introduced metrics that quantify hallucination sensitivity under visually coherent scene edits. 
              Experiments on <span class="model-name-gradient">HalluSegBench</span> with state-of-the-art vision-language segmentation models reveal that vision-driven hallucinations are significantly more prevalent than label-driven ones, with models often persisting in false segmentation, highlighting the need for counterfactual reasoning to diagnose grounding fidelity.
            </p>
          </div>
          <img src="./static/images/teaser.png" class="interpolation-image"
          alt="Interpolate start reference image." width="85%" />
        </div>
      </div>
  </div>
  </section>

  <section class="section" style="background-color:#dadada81">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3">✅ Contributions</h2>
          <div class="content has-text-justified">
            <ul class="fa-ul">
              <li><span class="fa-li"><i class="fa fa-star" style="color:#FFD700"></i></span><b>New Benchmark</b>. We present <span class="model-name">HalluSegBench</span>, 
                the first benchmark for evaluating segmentation hallucinations using counterfactual image-text pairs, 
                covering 1,340 pairs across 281 object classes. </li>
              <br>
              <li><span class="fa-li"><i class="fa fa-star" style="color:#FFD700"></i></span><b>Novel Metrics</b>. 
                We introduce four new metrics that quantify hallucination severity under visual/textual counterfactuals, 
                reveal over-reliance on semantic priors, and assess spatial plausibility of hallucinated masks.
              </li>
              <br>
              <li><span class="fa-li"><i class="fa fa-star" style="color:#FFD700"></i></span><b>Empirical Insights</b>. 
                Experiments on state-of-the-art vision-language segmentation models show they hallucinate more under visual edits than textual ones, 
                highlighting the need for counterfactual-based diagnostics.</li>
              </ol>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3">Quantitative Results</h2>
          <div class="content has-text-justified">
            <div style="text-align: center; padding: 0 0 20px 0;">
              <img src="./static/images/quat_result.png" class="interpolation-image" alt="HalluSegBench results." width="85%" />
              <p class="has-text-justified">
                Comparison of Reasoning Segmentation Models on <span class="model-name">HalluSegBench</span> Metrics, including textual and visual IoU drop (<code>&Delta;IoU<sub>textual</sub></code>, <code>&Delta;IoU<sub>visual</sub></code>), 
                factual and counterfactual Confusion Mask Score ( <code>CMS</code>), and the contrastive hallucination metric <code>CCMS</code>.              
              </p>
            </div>
          </div>
        </div>
      </div>
    </div>
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3">Qualitative Results</h2>
          <p class="has-text-justified" style="padding-bottom:30px;">
            <span class="model-name">HalluSegBench</span> demonstrates the hallucination severity of different reasoning-based segmentation models. 
            We present qualitative examples that illustrate the predictions of benchmarked models across the four query-image combinations, 
            along with the corresponding ground truth mask.
          </p>
          <!-- <div class="qual-example">
            <div class="image-container">
              <img src="static/images/example1.png" alt="Image 1" style="height: 600px; width: auto;">
            </div>
            <p class="caption has-text-centered">
              Here, <i>c</i> = “the middle elephant” and <i>c′</i> = “a rhinoceros”.
            </p>
          </div> -->
          <!-- <div class="qual-example"> -->
            <div>
              <img src="static/images/example3.png" alt="Image 2" style="height: 800px; width: auto;">
            </div>
            <p class="caption has-text-centered">
              Here, <i>c</i> = “full grown sheep” and <i>c′</i> = “a cow”.
            </p>
          <!-- </div> -->
          <!-- <div class="qual-example"> -->
            </br> 
            </br>
            </br>
           <div>
              <img src="static/images/example2.png" alt="Image 3" style="height: 800px; width: auto;">
            </div>
            <p class="caption has-text-centered">
              Here, <i>c</i> = “front cow” and <i>c′</i> = “front pig”.
            </p>
          <!-- </div> -->

        </div>
      </div>
    </div>
    </div>
    </div>
  </section>


  <!-- <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{,
  title={},
  author={},
  journal={},
  year={2025}
}</code></pre>
    </div>
  </section> -->


  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href=".">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="https://github.com/PLAN-Lab" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This site is built upon the work of <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>,
              made available under the <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>. We gratefully acknowledge 
              <a  href="https://arxiv.org/pdf/2308.00692">LISA</a>,
              <a href="https://arxiv.org/pdf/2311.03356">GLaMM</a>,
              <a href="https://arxiv.org/pdf/2312.02228">PixelLM</a>, and <a
                href="https://arxiv.org/pdf/2312.08366">SESAME</a>
                for open-sourcing their models.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>
</body>

</html>
