<!doctype html>
<html lang="en">
  <head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-48J3PYKGQ6"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-48J3PYKGQ6');
</script>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="description" content="Fine-Grained Preference Optimization Improves Spatial Reasoning in VLMs" />
    <title>Fine-Grained Preference Optimization Improves Spatial Reasoning in VLMs</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;500;700;800&display=swap" rel="stylesheet">
    <link rel="preconnect" href="https://cdnjs.cloudflare.com" crossorigin>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

    <link rel="stylesheet" href="../../assets/css/style.css" />
    <link rel="stylesheet" href="../../assets/css/projects.css" />
    <script src="../../assets/js/project-pages.js" defer></script>
    <link rel="icon" type="image/svg+xml" href="assets/images/favicon.svg">
</head>
  <body class="page-project">
    <div class="project-bg"></div>
    <div class="project-grid"></div>

    <nav class="glass-nav">
  <a href="../../index.html#hero" class="nav-logo">
    <img src="../../assets/images/logo.svg" alt="PLAN Lab Logo">
  </a>
  <div class="nav-menu">
    <a href="../../publications.html" class="nav-item" aria-label="Publications">
      <i class="fa-solid fa-layer-group"></i>
      <span>Publications</span>
    </a>
    <a href="../../index.html#team" class="nav-item" aria-label="Team">
      <i class="fa-solid fa-users"></i>
      <span>Team</span>
    </a>
    <a href="../../game.html" class="nav-item" aria-label="PLAN Cubes Game">
      <i class="fa-solid fa-cube"></i>
      <span>PLAN Cubes</span>
    </a>
    <a href="../../index.html#partners" class="nav-item" aria-label="Partner with Us">
      <i class="fa-solid fa-circle-nodes"></i>
      <span>Partner with Us</span>
    </a>
    <a href="../../index.html#contact" class="nav-item" aria-label="Join Us">
      <i class="fa-solid fa-paper-plane"></i>
      <span>Join Us</span>
    </a>
  </div>
</nav>

    <main>
<section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-2 publication-title" style="display: flex; align-items: center; justify-content: center; gap: 15px;"><img src="static/images/logo.png" alt="SpatialReasoner Logo" width="100px"><span>Fine-Grained Preference Optimization Improves Spatial Reasoning in VLMs</span></h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="/team/phd-yifan-shen" class="external-link" ><span class="illini-blue">Yifan Shen</span></a><sup class="illini-orange">1</sup>,</span>
              <span class="author-block">
                <a href="https://www.linkedin.com/in/yuanzhe-liu-upenn-ds/" class="external-link"><span class="illini-blue">Yuanzhe Liu</span></a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="https://www.linkedin.com/in/jingyuan-zhu-6a0ab3322/" class="external-link"><span class="illini-blue">Jingyuan Zhu</span></a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.irohxucao.com/" class="external-link"><span class="illini-blue">Xu Cao</span></a><sup class="illini-orange">1</sup>,
              </span>
              <span class="author-block">
                <a href="#" class="external-link"><span class="illini-blue">Xiaofeng Zhang</span></a><sup>3</sup>,
              </span>
              <span class="author-block">
                <a href="#" class="external-link"><span class="illini-blue">Yixiao He</span></a><sup class="illini-orange">1</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.linkedin.com/in/wenming-ye-0170b11/" class="external-link"><span class="illini-blue">Wenming Ye</span></a><sup>4</sup>,
              </span>
              <span class="author-block">
                <a href="https://rehg.org/" class="external-link"><span class="illini-blue">James Matthew Rehg</span></a><sup class="illini-orange">1</sup>,
              </span>
              <span class="author-block">
                <a href="/team/pi-ismini-lourentzou" class="external-link" ><span class="illini-blue">Ismini Lourentzou</span></a><sup class="illini-orange">1</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors" style="margin-top: 10px;">
              <div>
                <span class="author-block illini-orange"><sup class="illini-orange">1</sup>University of Illinois Urbana-Champaign</span>
                <span class="author-block"><sup>2</sup>University of Pennsylvania</span>
              </div>
              <div>
                <span class="author-block"><sup>3</sup>Shanghai Jiao Tong University</span>
                <span class="author-block"><sup>4</sup>Google</span>
              </div>
            </div>
            
            <!-- <div class="has-text-centered" style="margin: 5px 0;">
              <img src="./static/images/u_logo.png" alt="Affiliation Logos" style="height: 55px;">
            </div> -->

            <div class="has-text-centered" style="margin: 5px 0;">
              <span class="author-block illini-orange" style="font-size: 2.1rem;"><sup class="illini-orange">NeurIPS 2025</h1>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2506.21656.pdf" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://huggingface.co/PLAN-Lab/SpatialReasoner-R1" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      ðŸ¤—
                    </span>
                    <span>Model</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://github.com/PLAN-Lab/SpatialReasonerR1" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <div class="content has-text-justified">
          <span style="font-weight: bold;">TL;DR:</span> We propose a novel fine-grained preference optimization approach that significantly improves spatial reasoning capabilities in Vision-Language Models (VLMs). Our method leverages carefully designed preference data and training strategies to enhance spatial understanding without compromising general visual capabilities.
        </div>
        <div class="pdf-container">
          <img loading="lazy" decoding="async" src="./static/images/teaser.png" class="interpolation-image" alt="Workflow Overview">
        </div>
      </div>
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Current Vision-Language Models (VLMs) struggle with fine-grained spatial reasoning, particularly when multi-step logic and precise spatial alignment are required. In this work, we introduce <span style="color:rgb(26,78,138); font-weight:bold;">Spatial</span><span style="color:rgb(86,187,204); font-weight:bold;">Reasoner-R1</span> a vision-language reasoning model designed to address these limitations. To construct high-quality supervision for spatial reasoning, we design a Multi-Model Monte Carlo Tree Search (M3CTS) method that generates diverse, logically consistent Long Chain-of-Thought (LongCoT) reasoning trajectories. In addition, we propose fine-grained Direct Preference Optimization (fDPO), which introduces segment-specific preference granularity for descriptive grounding and logical reasoning, guided by a spatial reward mechanism that evaluates candidate responses based on visual consistency, spatial grounding, and logical coherence. Experimental results demonstrate that fDPO achieves an average improvement of 4.1% over standard DPO across spatial quality tasks, and a 9.0% gain in spatial quantity tasks. SpatialReasoner-R1, trained with fDPO, sets a new SoTA on SpatialRGPT-Bench, outperforming the strongest baseline by 9.4% in average accuracy, while maintaining competitive performance on general vision-language tasks.           </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3">âœ… Contributions</h2>
          <div class="content has-text-justified">
            <ul class="fa-ul">
              <li><span class="fa-li"><i class="fa fa-check"></i></span><b>SpatialReasoner-R1</b>. We introduce SpatialReasoner-R1, a VLM designed for fine-grained LongCoT spatial reasoning that effectively generates interpretable, step-by-step explanations directly from 2D images. SpatialReasoner-R1 establishes a new SoTA in spatial understanding tasks, while maintaining robust performance on general vision-language benchmarks.</li>
              <br>
              <li><span class="fa-li"><i class="fa fa-check"></i></span><b>Fine-grained Direct Preference Optimization</b>. To enhance training stability and precision, we propose a new fine-grained Direct Preference Optimization fDPO method that employs segment-specific learning updates tailored explicitly for descriptive grounding and logical reasoning.</li>
              <br>
              <li><span class="fa-li"><i class="fa fa-check"></i></span><b>Multi-Model Monte Carlo Tree Search</b>. To address the scarcity of high-quality spatial reasoning data, we introduce a data generation pipeline that combines Multi-Model Monte Carlo Tree Search  (M3CTS) with fine-grained spatial rewards, enabling the creation of diverse, logically consistent LongCoT trajectories for fine-grained preference training.</li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3">Method Overview</h2>
          <div class="content has-text-justified">
            <div class="pdf-container">
              <img loading="lazy" decoding="async" src="./static/images/workflow_c.png" class="interpolation-image" alt="Fine-Grained Preference Optimization">
            </div>
            <div class="horizontal-container">
              <p>Method Overview including <span style="color:rgb(26,78,138); font-weight:bold;">Spatial</span><span style="color:rgb(86,187,204); font-weight:bold;">Reasoner-R1</span> model architecture and training pipeline. Training pipeline consisting of three stages: (1) generating reasoning paths using M3CTS; (2) constructing fine-grained preference pairs via reward-based selection; (3) training with fine-grained DPO (fDPO) to optimize descriptive and logical reasoning separately.</p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3">Fine-Grained Spatial Rewards</h2>
          <div class="content has-text-justified">
            <div class="pdf-container">
              <img loading="lazy" decoding="async" src="./static/images/fdpo_c.png" class="interpolation-image" alt="Fine-Grained Preference Optimization">
            </div>
            <div class="horizontal-container">
                             <p>Fine-Grained Spatial Rewards. Candidate reasoning paths are decomposed into three aspects, <em>descriptive</em>, <em>spatial</em>, and <em>reasoning</em>, scored separately; the higher value in each row is marked by <span style="color: green;">âœ”</span> and the lower by <span style="color: red;">âœ–</span>.</p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3">Spatial Reasoning Evaluation</h2>
          <div class="content has-text-justified">
            <p>We conduct comprehensive evaluation on spatial reasoning tasks to demonstrate the effectiveness of our approach.</p>
            <div class="pdf-container" style="width: 65%; margin: 0 auto;">
              <img loading="lazy" decoding="async" src="./static/images/result.png" class="interpolation-image" alt="Comparison Results">
            </div>
            <p>Spatial reasoning success rates (â†‘) on SpatialRGPT-Bench. "/" indicates that the model refuses to provide a response for that metric. <span style="color:rgb(26,78,138); font-weight:bold;">Spatial</span><span style="color:rgb(86,187,204); font-weight:bold;">Reasoner-R1</span> 8B, trained with fDPO, establishes a new SoTA in spatial reasoning.</p>
          </div>
        </div>
      </div>
    </div>
    
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3">Examples and Results</h2>
          <p class="has-text-justified" style="padding-bottom:30px;">
            <span style="color:rgb(26,78,138); font-weight:bold;">Spatial</span><span style="color:rgb(86,187,204); font-weight:bold;">Reasoner-R1</span> demonstrates improved spatial reasoning across various scenarios and object types:
          </p>
          
          <div style="text-align: center; padding: 0 0 30px 0;">
            <div class="pdf-container" style="width: 80%; margin: 0 auto;">
              <img loading="lazy" decoding="async" src="./static/images/spatial_comparison_c.png" class="interpolation-image" alt="Spatial Comparison">
            </div>
            <p class="has-text-justified" style="margin-top: 20px;">
              <!-- Comparison of spatial reasoning performance across different models and approaches. -->
            </p>
          </div>

          <div style="text-align: center; padding: 0 0 20px 0;">
            <div class="pdf-container" style="width: 80%; margin: 0 auto;">
              <img loading="lazy" decoding="async" src="./static/images/additionexample1.png" class="interpolation-image" alt="Additional Examples">
            </div>
            <p class="has-text-justified" style="margin-top: 20px;">
              <!-- Additional examples showing the improved spatial reasoning capabilities of our fine-grained preference optimized models. -->
            </p>
          </div>

          <div style="text-align: center; padding: 0 0 20px 0;">
            <div class="pdf-container" style="width: 80%; margin: 0 auto;">
              <img loading="lazy" decoding="async" src="./static/images/additional_example2.png" class="interpolation-image" alt="Additional Examples 2">
            </div>
            <p class="has-text-justified" style="margin-top: 20px;">
              <!-- More examples demonstrating enhanced spatial reasoning capabilities through fine-grained preference optimization. -->
            </p>
          </div>
        </div>
      </div>
    </div>
    
  </section>


  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{shen2025finegrainedpreferenceoptimizationimproves,
      title={Fine-Grained Preference Optimization Improves Spatial Reasoning in VLMs}, 
      author={Yifan Shen and Yuanzhe Liu and Jingyuan Zhu and Xu Cao and Xiaofeng Zhang and Yixiao He and Wenming Ye and James Matthew Rehg and Ismini Lourentzou},
      year={2025},
      eprint={2506.21656},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2506.21656}, 
}</code></pre>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="https://arxiv.org/pdf/2506.21656.pdf">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="https://github.com/PLAN-Lab" disabled>
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This site is built upon the work of <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>,
              made available under the <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>
    </main>
  </body>
</html>
