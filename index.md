---
title: Home
---

# Our Mission

Our research lab is broadly interested in multimodal machine learning and learning with limited supervision. We are particularly interested in building intelligent task assistants that can fuse linguistic, visual, and other types of modalities to perceive and interact with the world. Current language + vision projects involve multimodal representation learning, contrastive self-supervision, embodied AI, video localization and multi-agent communication. Applications include healthcare, medical imaging, manufacturing and misinformation detection.

{:.center}

{%
  include link.html
  type="github"
  icon=""
  text="GitHub"
  link="PLAN-Lab"
  style="button"
%}
